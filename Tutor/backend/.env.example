# üß† TutorGPT Backend Configuration
# ===========================================
# Copy this file to .env: cp .env.example .env
# Then add YOUR API key and choose your model!
# ===========================================

# üîë REQUIRED: Your API Key
# ===========================================
# ADD YOUR API KEY HERE (from any provider below):
#
# 1Ô∏è‚É£ Google Gemini (Free): https://aistudio.google.com/apikey
# 2Ô∏è‚É£ OpenAI: https://platform.openai.com/api-keys
# 3Ô∏è‚É£ Groq (Fast & Free): https://console.groq.com/keys
# 4Ô∏è‚É£ DeepSeek: https://platform.deepseek.com/
# 5Ô∏è‚É£ OpenRouter (100+ models): https://openrouter.ai/
#
GEMINI_API_KEY=your_api_key_here

# üéØ OPTIONAL: Choose Your Model
# ===========================================
# Default: gemini-2.0-flash-exp (Google Gemini)
# Examples:
#   - gemini-2.0-flash-exp (Gemini)
#   - gpt-4o (OpenAI)
#   - llama-3.1-70b-versatile (Groq)
#   - deepseek-chat (DeepSeek)
#   - google/gemini-flash-1.5 (OpenRouter)
#
GEMINI_MODEL=gemini-2.0-flash-exp

# üåê OPTIONAL: API Base URL
# ===========================================
# Default: Gemini endpoint
# Change based on your provider:
#   - Gemini: https://generativelanguage.googleapis.com/v1beta/openai/
#   - OpenAI: https://api.openai.com/v1
#   - Groq: https://api.groq.com/openai/v1
#   - OpenRouter: https://openrouter.ai/api/v1
#
API_BASE_URL=https://generativelanguage.googleapis.com/v1beta/openai/

# üìö EMBEDDINGS: For RAG (Semantic Search)
# ===========================================
# Google Gemini API Key (same key or different)
GOOGLE_API_KEY=your_api_key_here

# Embedding model (Google Gemini)
EMBEDDING_MODEL=text-embedding-004

# =================
# Application Settings
# =================

# Environment (development, staging, production)
ENVIRONMENT=development

# FastAPI settings
HOST=0.0.0.0
PORT=8000
DEBUG=True

# CORS Origins (comma-separated list for production)
# For development, use: http://localhost:3000,http://localhost:8000
CORS_ORIGINS=http://localhost:3000,http://localhost:8000

# =================
# Database Settings
# =================

# SQLite database path (relative to backend/ directory)
DATABASE_PATH=./data/sessions.db

# =================
# Vector Store (ChromaDB)
# =================

# ChromaDB persist directory (relative to backend/ directory)
CHROMADB_PATH=./data/embeddings

# Gemini embedding model
EMBEDDING_MODEL=gemini-embedding-001

# Embedding dimensions (768 recommended, 3072 max quality)
EMBEDDING_DIMENSIONS=768

# =================
# Agent Configuration
# =================

# Gemini model for agent (via OpenAI-compatible API)
# Options: gemini-2.0-flash-exp, gemini-2.0-flash, gemini-1.5-pro
AGENT_MODEL=gemini-2.0-flash

# Agent temperature (0.0-1.0, lower = more consistent)
AGENT_TEMPERATURE=0.7

# Max tokens for agent responses
AGENT_MAX_TOKENS=1000

# =================
# RAG Configuration
# =================

# Number of chunks to retrieve per RAG search
RAG_TOP_K=5

# Chunk size for book content (tokens)
CHUNK_SIZE=512

# Chunk overlap (tokens)
CHUNK_OVERLAP=50

# =================
# Session Settings
# =================

# Session expiry (days)
SESSION_EXPIRY_DAYS=30

# Context window size (number of recent messages to prioritize)
CONTEXT_WINDOW_SIZE=7

# =================
# Performance Settings
# =================

# Response timeout (seconds)
RESPONSE_TIMEOUT=10

# Rate limit (requests per minute per session)
RATE_LIMIT_PER_MINUTE=10

# =================
# Logging
# =================

# Log level (DEBUG, INFO, WARNING, ERROR, CRITICAL)
LOG_LEVEL=INFO

# Log file path (relative to backend/ directory)
LOG_FILE=./data/logs/tutorgpt.log

# =================
# Testing (Optional)
# =================

# Test database path (for pytest)
TEST_DATABASE_PATH=./data/test_sessions.db

# Test ChromaDB path
TEST_CHROMADB_PATH=./data/test_embeddings
